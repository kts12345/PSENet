{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "import collections\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "\n",
    "from dataset import IC15TestLoader\n",
    "import models\n",
    "import util\n",
    "# c++ version pse based on opencv 3+\n",
    "#from pse import pse\n",
    "#python pse\n",
    "from pypse import pse as pypse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_3c(img):\n",
    "    img = img.reshape(img.shape[0], img.shape[1], 1)\n",
    "    img = np.concatenate((img, img, img), axis=2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(idx, img_paths, imgs, output_root):\n",
    "    if not os.path.exists(output_root):\n",
    "        os.makedirs(output_root)\n",
    "    \n",
    "    col = []\n",
    "    for i in range(len(imgs)):\n",
    "        row = []\n",
    "        for j in range(len(imgs[i])):\n",
    "            # img = cv2.copyMakeBorder(imgs[i][j], 3, 3, 3, 3, cv2.BORDER_CONSTANT, value=[255, 0, 0])\n",
    "            row.append(imgs[i][j])\n",
    "        res = np.concatenate(row, axis=1)\n",
    "        col.append(res)\n",
    "    res = np.concatenate(col, axis=0)\n",
    "    img_name = img_paths[idx].split('/')[-1]\n",
    "    #print(idx, '/', len(img_paths), img_name)\n",
    "    cv2.imwrite(output_root + img_name, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_result_as_txt(image_name, bboxes, path):\n",
    "    filename = util.io.join_path(path, 'res_%s.txt'%(image_name))\n",
    "    lines = []\n",
    "    for b_idx, bbox in enumerate(bboxes):\n",
    "        values = [int(v) for v in bbox]\n",
    "        line = \"%d, %d, %d, %d, %d, %d, %d, %d\\n\"%tuple(values)\n",
    "        lines.append(line)\n",
    "    util.io.write_lines(filename, lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_from_points(points):\n",
    "    \"\"\"\n",
    "    Returns a Polygon object to use with the Polygon2 class from a list of 8 points: x1,y1,x2,y2,x3,y3,x4,y4\n",
    "    \"\"\"\n",
    "    resBoxes=np.empty([1, 8],dtype='int32')\n",
    "    resBoxes[0, 0] = int(points[0])\n",
    "    resBoxes[0, 4] = int(points[1])\n",
    "    resBoxes[0, 1] = int(points[2])\n",
    "    resBoxes[0, 5] = int(points[3])\n",
    "    resBoxes[0, 2] = int(points[4])\n",
    "    resBoxes[0, 6] = int(points[5])\n",
    "    resBoxes[0, 3] = int(points[6])\n",
    "    resBoxes[0, 7] = int(points[7])\n",
    "    pointMat = resBoxes[0].reshape([2, 4]).T\n",
    "    return plg.Polygon(pointMat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "def test(args):\n",
    "    data_loader = IC15TestLoader(long_size=args.long_size)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        data_loader,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        drop_last=True)\n",
    "\n",
    "    # Setup Model\n",
    "    if args.arch == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=True, num_classes=7, scale=args.scale)\n",
    "    elif args.arch == \"resnet101\":\n",
    "        model = models.resnet101(pretrained=True, num_classes=7, scale=args.scale)\n",
    "    elif args.arch == \"resnet152\":\n",
    "        model = models.resnet152(pretrained=True, num_classes=7, scale=args.scale)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model = model.cuda()\n",
    "    \n",
    "    if args.resume is not None:                                         \n",
    "        if os.path.isfile(args.resume):\n",
    "            print((\"Loading model and optimizer from checkpoint '{}'\".format(args.resume)))\n",
    "            checkpoint = torch.load(args.resume)\n",
    "            \n",
    "            # model.load_state_dict(checkpoint['state_dict'])\n",
    "            d = collections.OrderedDict()\n",
    "            for key, value in list(checkpoint['state_dict'].items()):\n",
    "                tmp = key[7:]\n",
    "                d[tmp] = value\n",
    "            model.load_state_dict(d)\n",
    "\n",
    "            print((\"Loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume, checkpoint['epoch'])))\n",
    "            sys.stdout.flush()\n",
    "        else:\n",
    "            print((\"No checkpoint found at '{}'\".format(args.resume)))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    total_frame = 0.0\n",
    "    total_time = 0.0\n",
    "    for idx, (org_img, img) in tqdm(list(enumerate(test_loader))):\n",
    "      #  print(('progress: %d / %d'%(idx, len(test_loader))))\n",
    "      #  sys.stdout.flush()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #img = Variable(img.cuda(), volatile=True)\n",
    "            img = img.cuda()\n",
    "            org_img = org_img.numpy().astype('uint8')[0]\n",
    "            text_box = org_img.copy()\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            start = time.time()\n",
    "\n",
    "            outputs = model(img)\n",
    "            outputs = outputs.detach()\n",
    "\n",
    "            score = torch.sigmoid(outputs[:, 0, :, :])\n",
    "            outputs = (torch.sign(outputs - args.binary_th) + 1) / 2\n",
    "    \n",
    "            text = outputs[:, 0, :, :]\n",
    "            kernels = outputs[:, 0:args.kernel_num, :, :] * text\n",
    "    \n",
    "            score = score.data.cpu().numpy()[0].astype(np.float32)\n",
    "            text = text.data.cpu().numpy()[0].astype(np.uint8)\n",
    "            kernels = kernels.data.cpu().numpy()[0].astype(np.uint8)\n",
    "            \n",
    "            # c++ version pse\n",
    "            #pred = pse(kernels, args.min_kernel_area / (args.scale * args.scale))\n",
    "            # python version pse\n",
    "            pred = pypse(kernels, args.min_kernel_area / (args.scale * args.scale))\n",
    "            \n",
    "            # scale = (org_img.shape[0] * 1.0 / pred.shape[0], org_img.shape[1] * 1.0 / pred.shape[1])\n",
    "            scale = (org_img.shape[1] * 1.0 / pred.shape[1], org_img.shape[0] * 1.0 / pred.shape[0])\n",
    "            label = pred\n",
    "            label_num = np.max(label) + 1\n",
    "            bboxes = []\n",
    "            for i in range(1, label_num):\n",
    "                points = np.array(np.where(label == i)).transpose((1, 0))[:, ::-1]\n",
    "    \n",
    "                if points.shape[0] < args.min_area / (args.scale * args.scale):\n",
    "                    continue\n",
    "    \n",
    "                score_i = np.mean(score[label == i])\n",
    "                if score_i < args.min_score:\n",
    "                    continue\n",
    "    \n",
    "                rect = cv2.minAreaRect(points)\n",
    "                bbox = cv2.boxPoints(rect) * scale\n",
    "                bbox = bbox.astype('int32')\n",
    "                bboxes.append(bbox.reshape(-1))\n",
    "    \n",
    "            torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "            total_frame += 1\n",
    "            total_time += (end - start)\n",
    "            #print(('fps: %.2f'%(total_frame / total_time)))\n",
    "            #sys.stdout.flush()\n",
    "    \n",
    "            image_name = data_loader.img_paths[idx].split('/')[-1].split('.')[0]\n",
    "            write_result_as_txt(image_name, bboxes, 'outputs/submit_ic15/')\n",
    "            \n",
    "            for bbox in bboxes:\n",
    "                cv2.drawContours(text_box, [bbox.reshape(4, 2)], -1, (0, 255, 0), 2)\n",
    "    \n",
    "            \n",
    "            text_box = cv2.resize(text_box, (text.shape[1], text.shape[0]))\n",
    "            debug(idx, data_loader.img_paths, [[text_box]], 'outputs/vis_ic15/')\n",
    "\n",
    "    cmd = 'cd %s;zip -j %s %s/*'%('./outputs/', 'submit_ic15.zip', 'submit_ic15');\n",
    "    print(cmd)\n",
    "    sys.stdout.flush()\n",
    "    util.cmd.cmd(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and optimizer from checkpoint './checkpoints/pse_net_checkpoint_538.pth.tar'\n",
      "Loaded checkpoint './checkpoints/pse_net_checkpoint_538.pth.tar' (epoch 536)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701480c9f88f4e188122eee0117a6177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=150), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 150 img_84.jpg\n",
      "1 / 150 img_95.jpg\n",
      "2 / 150 img_94.jpg\n",
      "3 / 150 img_123.jpg\n",
      "4 / 150 img_92.jpg\n",
      "5 / 150 img_109.jpg\n",
      "6 / 150 img_28.jpg\n",
      "7 / 150 img_59.jpg\n",
      "8 / 150 img_134.jpg\n",
      "9 / 150 img_117.jpg\n",
      "10 / 150 img_89.jpg\n",
      "11 / 150 img_108.jpg\n",
      "12 / 150 img_22.jpg\n",
      "13 / 150 img_144.jpg\n",
      "14 / 150 img_87.jpg\n",
      "15 / 150 img_31.jpg\n",
      "16 / 150 img_71.jpg\n",
      "17 / 150 img_103.jpg\n",
      "18 / 150 img_47.jpg\n",
      "19 / 150 img_141.jpg\n",
      "20 / 150 img_122.jpg\n",
      "21 / 150 img_142.jpg\n",
      "22 / 150 img_146.jpg\n",
      "23 / 150 img_27.jpg\n",
      "24 / 150 img_74.jpg\n",
      "25 / 150 img_110.jpg\n",
      "26 / 150 img_125.jpg\n",
      "27 / 150 img_99.jpg\n",
      "28 / 150 img_113.jpg\n",
      "29 / 150 img_69.jpg\n",
      "30 / 150 img_124.jpg\n",
      "31 / 150 img_39.jpg\n",
      "32 / 150 img_119.jpg\n",
      "33 / 150 img_17.jpg\n",
      "34 / 150 img_96.jpg\n",
      "35 / 150 img_150.jpg\n",
      "36 / 150 img_115.jpg\n",
      "37 / 150 img_16.jpg\n",
      "38 / 150 img_50.jpg\n",
      "39 / 150 img_111.jpg\n",
      "40 / 150 img_80.jpg\n",
      "41 / 150 img_60.jpg\n",
      "42 / 150 img_62.jpg\n",
      "43 / 150 img_75.jpg\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Hyperparams')\n",
    "parser.add_argument('--arch', nargs='?', type=str, default='resnet50')\n",
    "parser.add_argument('--resume', nargs='?', type=str, default='./checkpoints/pse_net_checkpoint_538.pth.tar',    \n",
    "                    help='Path to previous saved model to restart from')\n",
    "parser.add_argument('--binary_th', nargs='?', type=float, default=1.0,\n",
    "                    help='binary th')\n",
    "parser.add_argument('--kernel_num', nargs='?', type=int, default=7,\n",
    "                    help='')\n",
    "parser.add_argument('--scale', nargs='?', type=int, default=1,\n",
    "                    help='scale')\n",
    "parser.add_argument('--long_size', nargs='?', type=int, default=2240,\n",
    "                    help='long size')\n",
    "parser.add_argument('--min_kernel_area', nargs='?', type=float, default=5.0,\n",
    "                    help='min kernel area')\n",
    "parser.add_argument('--min_area', nargs='?', type=float, default=800.0,\n",
    "                    help='min area')\n",
    "parser.add_argument('--min_score', nargs='?', type=float, default=0.93,\n",
    "                    help='min score')\n",
    "\n",
    "args = parser.parse_args('')\n",
    "test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
